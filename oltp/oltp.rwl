# Copyright (c) 2021 Oracle Corporation
# Licensed under the Universal Permissive License v 1.0
# as shown at https://oss.oracle.com/licenses/upl/
#
# This file MUST be named $RWLOLTP_NAME.rwl where
# $RWLOLTP_NAME is your project name.
#
# The file contains everything that controls running
# the normaly, continuous or scalability workloads
#
# The variables are included in decreasing order
# of likelihood of changing.

# Set names of directories for awr and for results
# Note that these directory name CANNOT have
# any white space in them and that those shown here
# are merely samples
awrdirectory := "/NOTSET/var/www/html/key";
resultsdir:="/NOTSET/home/results/key";

# The rwloltp suite uses several different connect
# strings for different purposes. In many casess
# they can have the same value.
# The samples below are just names and they will
# therefore point to entries in your tnsnames.ora
# file. You can also use //host/service style
# connect strings.

# Connect string normal, dedicated connections
# that will not be using a session pool:
normal_connect := "sample_tp";

# The connect string for the ordinary session
# pools that handle most of the workload,
# namely all transactions that are considered short
pool_connect := "sample_tp";

# The connect string for what is called the
# "batch" workload that handle longer transactions
batch_connect := "sample_tp";

# Both of these pools will be using a session pool
# unless pool_type and/or batch_type explicitly
# are set to either "drcp" or "dedicated"
# pool_type := "drcp";
# batch_type := "drcp";
# Note that the term "batch" here really isn't batch
# it is just a pool that deals with transactions
# that are longer than the typical oltp ones.

# If you want to run oltprun/oltpcore to simulate
# more real batch type activity in stead of oltp
# run them with the -b option, which will turn
# on simulatebatch. If you want to experiment
# with that, uncomment the next three lines:
# if simulatebatch then 
#   pool_type := "dedicated";
# end if;

# There are two different connect strings
# (and also username/{password})
# that are used when making connections
# as a DBA user. 
#
# The first is used when creating schemas.
# If you have a connect string that allows
# parallel execution (which is e.g. the case
# when your database is an ATP database),
# using that implies faster schema creation
cruser_connect := "sample_tpurgent";
cruser_username := "system";
cruser_password := "{password}";
# The default tablespace to be used for all test data
default_tablespace := "data";

# The next connect string, username and password
# are used when when doing gv$ queries
# It will often be the same as above, except that
# the connect string should be _tp when your
# database is an autonomous database.
system_connect := "sample_tp";
system_username := "system";
system_password := "{password}";

# The next three are used for awr snapshots 
# and reporting. If not set (i.e. set to the empty string)
# the values will be the same as the three previous
# ones
sysawr_connect := "";
sysawr_username := "";
sysawr_password := "";

# The next variables are for the RWL*Load Simulator
# repository.  If you have one you can use, that
# is recommended, otherwise, you can put a stand alone
# repository in the same database you are testing.

# Do you have an existing repository, set to 0
# otherwise 1, and the repository will be put
# in your database under test
results_in_test := 1; 
# In the latter case you also need to 
# set rwloadsimdir to point to the admin
# directory of your rwloadsim installation

# Set username, password and connect string for
# the RWP*Load Simulator repository
# results_username must be upper case
results_username := "RWLOADSIM";
results_password := "{password}";

if results_in_test then
  results_connect := "sample_tp";
  # If creating the repository, we need to know
  # where to find the files with ddl
  rwloadsimdir := "/NOTSET/home/rwloadsim/admin";
else
  results_connect := "//server/database";
end if;

# There will be five ordinary users created in your
# database under test.  These are set here.
# Note that all user names must be in upper case.

# Two schemas containing the AW (Aritifical Workload)
# tables:
rwl_aw1_username := "RWLAW1";
rwl_aw1_password := "{password}";
rwl_aw2_username := "RWLAW2";
rwl_aw2_password := "{password}";

# This is the schema containing the OE tables
rwl_oe_username := "RWLOE";
rwl_oe_password := "{password}";

# And finally two runtime users
rwl_run1_username := "RWLRUN1"; 
rwl_run1_password := "{password}";
rwl_run2_username := "RWLRUN2";
rwl_run2_password := "{password}";
# We need to be able to do various queries against
# gv$session (and others) with a predicate that
# returns our actual sessions.  For this, we
# need a like condition that mathces the runtime
# usernames shown above; again upper case is needed
rwl_run_like := "RWLRUN_";

# Next a text that will be put as (part of) the title
# on several html and graphics files.  Put something
# that makes it easy for a human to understand what
# this is about
rwl_title := "rwl oltp development test";

# The svg files created are clickable, but that
# assumes the necessary javascript files are made
# available externally though a browser.
# This setting depends on your version of gnuplot.
# You must copy the contents of the js 
# directory to /var/www/html.
gnuplotjs := "/usr/share/gnuplot/4.6/js";

# The svg files created for ash can be large 
# and may fill your awr directory too fast. To
# only generate the png file, set this to 0:
# largeashok := 0;

# The next parameter tells how many times
# we double the size of the aw_cols table
# that is randomly read via extremely poorly
# clustered indexes. If the resulting size
# is set higher than the expected largest buffer
# cache your database supports, you will get a 
# high amount of single or multi block buffered
# reads.
# Note that initially the table is around 256MB
# so the default value for this parameter of 4
# implies a resulting size of 4GB.
# Some other values and resulting sizes are:
# 1 -  Â½GB
# 2 -  1GB
# 4 -  4GB
# 6 - 16GB
# 7 - 32GB
# aw_cols_256MB_doublings := 4;
#
# The next parameter sets how the aw_cols table is
# accessed.
# If null (the default), all rows will be uniformly
# read, so if the table is larger than your buffer
# cache, you will get massive reads.
# You can therefore set a skew value, and the higher the
# value, the more skew the distribution of rows queried
# making the buffer cache more efficient causing less reads.
# Some very rough examples: 
#   1 - effectively whole table accessed
#   5 - 50% queries will be 67% of table, 90% queries will be 95% of table
#  20 - 50% queries will be 33% of table, 90% queries will be 83% of table
# 100 - 50% queries will be  9% of table, 90% queries will be 50% of table
# You typically need to experiment, in particular if your aw_cols
# table does not fit in your buffer cache.
# aw_cols_skew := null; # null is the default

# The aw_cols_query_factor tells how many rows are read for each
# query of the aw_cols tables. Due to the extremely poor clustering
# factor for the indexes, it also tells the number of blocks accessed
# and potentially read if they are not in the buffer cache.
# You will need to experiment, with the default value of 50 being
# a good starting point.
# aw_cols_query_factor := 50;



# Very few sessions are not using a session pool but are instead
# created initially and never terminated. This is against
# recommended practice, but can be used to e.g. test how
# Transparent Application Continutity deals with failover
# of such long running sessions. Set the following to 
# not have these sessions created.
# dontdolong := 0;      # Set to 1 to avoid sessions that never exit

# If you are on RAC and have high load, the artificial
# workload may not scale well unless it is known
# how many instances there are. You can often leave this
# unchanged, but for very high workload on RAC, set it
# to the actual number of instances that will be put under test
# aw_instances := 0; # 0 means don't know this is RAC

# If you want a burst to happen during the run, set these:
# This is mostly done for the scalability tests, not
# for continuous using oltpforever
# burst_start := 300; 	# when does burst start
# burst_length := 0; 	# how long is it (zero means no burst)
# burst_factor := 2.0;	# factor to increase arrival rate (1.0 means nothing)
#
# You can also add a burst in number of worker threads
# Note that if you do the following together with pool_type="dedicated"
# there will be an actual surge in dedicated connections at the start
# of the burst; this again means a risk of a database side connection storm
# wburst_count :=   0;   # default 0 means don't do it
# wburst_start := 360;   # when to start
# wburst_length := 10;   # length in seconds
# You can use something like the following, if you want the burst
# to be gradual and separated by 5 seconds per processes
# rather than concurrently in all:
# wburst_start := 360 + 5*procnumber;

# You can also add an activity burst, which in particular
# can be used to show the effect of session changing from
# idle to active if you are using dedicated connections. 
# An activity burst splits the run at a certain point in
# time, before that time the activity comes from a lower
# number of threads that therefore should have a
# higher arrival rate.
# After the point in time, the load is spread
# among all workers. The result is that at the certain
# split time, lots of connections will change from idle
# to active and therefore require (soft) parse of lots
# of SQL.

# If aburst_workers is null (default) this is not in effect
# otherwise, it must be a figure >0 and <threadcount being the
# number of workers that are active before the split time.
#
# The following example figures will imply a total even
# load throught the run, but for the first 120s, the load
# comes from only 25 worker threads.
# aburst_workers := 25; 
# aburst_pre_factor := 2.0; # factor for load before split
# aburst_post_factor := 1.0; # factor for load after split
# aburst_split_time := 120; # time when the workload changes

#
# There is also a possibilty for an implicit burst that
# comes from a temporary reduction in session pool sizes.
# This will only have effect when pool_type has its default
# value of "sessionpool", and rwloadsim must be release
# 2.3.4 or later
# delay_start := 0;      # Time when pool is reduced
# delay_length := 0;     # period of reduced pool, if 0, don't do it
# delay_min_pool := 0;   # min pool size during delay
# delay_max_pool := 1;   # max pool size during delay

# The following is the single parameter that sets the overall scale of
# the workload. Initially, leave it at the default.
# ratefactor := 0.2;    # proportionally changes load (default 0.2)

# Rather than a constant workload, you can make it gradually increase
# during the run by setting rategradient.
# If set to NULL or 0, same rate through whole run; this is the default
# Otherwise the workload will start 100*rategradient % lower
# and finish 100*rategradient % higher.
# The value must be in the range [0.0;1.0]
# As an example, if you uncomment this following line
# rategradient := 0.25;
# the rate will gradually increase from 75% to 125%.

# If using the oltpforever command to run continously, this parameter
# sets the number of processes in oltpforever (and oltpforever2)
# forever_proccount := 1;      # process count per side in continuous tests 
# Heading to be put on top of the daily reports created by oltpdaily
rwl_heading := "heading for daily oltp";
# Name of file that will contain links to all the daily reports
rwl_daily_html := "daily.html";


# If your database does not have partitioning enabled, set this to 0
# orders_hashcount := 8;# number of hash subpartitions in orders/order_items

# This is the time between each backgroun process start in the loop
# inside oltpcore. If you find process start or the assocated connection
# creation to take too long, increase this.
# script_ramp := 0.5;   # Time in seconds between process start; default 0.5

# The size of the cursor cache of the default pool influences parsing
# The default is 40, higher value means less parsing and vice versa
# cursor_cache_size := 40;

# You can modify the aggresiveness of logons by changing the time
# OCI waits until it disconnects an unused session in the pool
# rwl_pool_release := 5.0; # default is 5.0

# If you observe connection storm like behvior in the start of runs
# you can try increasing this value
# rampfactor := 0.1;    # Time in seconds between each thread start

# The following are used for external control, i.e. to change certain
# setting during a run. 
# The values shown here are the default ones, that can be set by
# calling oltpxcset --default

# xc_enabled := 0;         # Unless set, external control isn't used
# xc_ratefactor  := 1.0;   # load multiplier for the standard ratefactor
# xc_loadfactor  := 1.0;   # proportion threads active; max 1
# xc_hardparse   := 0;     # do hard parse
# xc_minpool     := 3;     # pool minimum size
# xc_maxpool     := 10;    # pool maximum size
# xc_cursorcache := 40;    # size of cursor cache
# xc_cursorleak  := 0.0;   # chance of cursor leak
# xc_sessionleak := 0.0;   # chance of session leak
# xc_sessionwait := 120;   # seconds timeout waitit for a free session, 0 for no timeout
# xc_stopnow     := 0;     # run should stop
# xc_logoffrate  := 0.0;   # logoff rate, used to cause increased logon rate

# Some can also be set when xc_control is not used
# hardparse := 0;          # make hard parse, currently only 0, 1 or 2
# logoffrate := 0.0;       # in the range [0;1]

# The following parameters rarely changed
# rwl_min_pool := 3;
# rwl_max_pool := 10;   # to experiment with variation in session pool size
# rwl_min_batch := 0;
# rwl_max_batch := 2;   # same for the batch pool
# threadcount := 50;    # number of worker threads
# Note that you probably want to have much fewer threads if simulatebatch
# (set via -b option to oltprun) is in use. As an example, uncomment
# the following three lines:
# if simulatebatch then 
#   threadcount := 2;
# end if;

# query_order_max_limit := 5000000;
			# How far back in time to look for orders

# If you observe that you have too much DML compared to queries in your
# database, increase the following parameter.
# query_factor := 1.0;

# The rest should almost never be changed unless you are 
# developing this code.  For details, see parameters.rwl
# makeorder_weight := 15.0; # create orders, i.e. DML and query
# queryorder_weight := 45.0; # simple query
# searchproduct_weight := 2.0; # pure query with scans
# makeinvoices_weight := 0.0; # make invoices, quite heavy, now only done in batch
# complex_query_weight := 1.5; # complex query with cpu usage
# stockup_weight := 0.2; # quite heavy DML, also done as batch
# aw_transaction_weight := 40.0; # Artificial transaction
# awindex_query_weight := 50.0; # Aritificial query likely to use I/O
# shiporder_weight := 0.05; # Can highly impact TX contention. Do not set higher than 0.05

# pool_size_interval := 300; # Set the frequence of saving shared pool, buffer cache sizes

# Do not modify these
# max_warehouse := 10;
# max_product := 10000;
# max_customer := 1000;

